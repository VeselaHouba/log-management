filter {
  ######## POSTGRES ############
  if ( [fields][logtype] == "postgres" ) {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{POSTGRESQL2}','%{POSTGRESQL3}','%{POSTGRESQL4}'
        ]
      }
    }
    date {
      match => [
        "datetime",
        "yyyy-MM-dd HH:mm:ss",
        "yyyy-MM-dd HH:mm:ss.SSS"
      ]
    }

  ######### NGINX ACCESS ###
  } else if ( [fields][logtype] == "nginx_access" ) {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{NGINXACCESS3}'
        ]
      }
    }
    date {
      match => [
        "datetime",
        "dd/MMM/yyyy:HH:mm:ss Z"
      ]
    }

  ######### HTTP ACCESS ###
  } else if ( [fields][logtype] == "httpd_access" ) {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{HTTPD_BS}'
        ]
      }
    }
    date {
      match => [
        "datetime",
        "dd/MMM/yyyy:HH:mm:ss Z"
      ]
    }

  ######### communicator ###
  } else if ( [fields][logtype] == "communicator" ) {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{COMMUNICATOR}'
        ]
      }
    }
    # since we are currently parsing only time field
    # we don't need message twice
    if "_grokparsefailure" not in [tags] {
      mutate {
        remove_field => [
          "message"
        ]
      }
    }
    if [datetime] {
      date {
        match => [
          "datetime",
          "yyyy-MM-dd HH:mm:ss"
        ]
      }
    }

  ######### admintool ###
  } else if ( [fields][logtype] == "admintool" ) {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{ADMINTOOL}'
        ]
      }
    }
    if "_grokparsefailure" not in [tags] {
      mutate {
        remove_field => [
          "message"
        ]
      }
    }
    if [datetime] {
      date {
        match => [
          "datetime",
          "yyyy-MM-dd HH-mm-ss"
        ]
      }
    }

    ######### fe ###
    } else if ( [fields][logtype] == "fe" ) {
      grok {
        patterns_dir => "/etc/logstash/patterns/"
        match => {
          "message" => [
            '%{FE}'
          ]
        }
      }
      if "_grokparsefailure" not in [tags] {
        mutate {
          remove_field => [
            "message"
          ]
        }
      }
      if [datetime] {
        date {
          match => [
            "datetime",
            "yyyy-MM-dd HH-mm-ss"
          ]
        }
      }


  ######### OTHER ##########
  } else {
    grok {
      patterns_dir => "/etc/logstash/patterns/"
      match => {
        "message" => [
          '%{SYSLOG_JSON}',
          '%{TIMESTAMP_ISO8601:datetime}:%{DATA:UUID}:%{LOGLEVEL:Loglevel}:%{DATA:LoggerName}:%{GREEDYDATA:msg}',
          '%{NGINXACCESS2}',
          '%{SYSLOG}',
          '.*?\[%{S_TIMESTAMP:datetime}\].*?'
        ]
      }
    }
    date {
      match => ["datetime",
        "ISO8601",
        "yyyy-MM-dd HH:mm:ss.SSSSSS",
        "yyyy-MM-dd HH:mm:ss.SSS",
        "yyyy-MM-dd HH:mm:ss",
        "dd-MMM-yyyy HH:mm:ss"
      ]
    }
    # https://redmine.betsys.com/issues/11257
    # regex for time with microseconds
    if [ident] =~ '/^.*\[([0-9]|-)*\s([0-9]|:)*\.[0-9]{1,6}.*\].*$/' {
      grok {
        patterns_dir => "/etc/logstash/patterns/"
        match => { "ident" => '%{S_TIMESTAMP:exacttime}' }
      }
      date {
        match => [ "exacttime","yyyy-MM-dd HH:mm:ss.SSSSSS" ]
      }
    }
    # extract status code from response
    if ( [LoggerName] =~ "response.status" ) {
      grok {
        match => {
          "msg" => "%{NUMBER:StatusCode:int}"
        }
      }
    }
  }
}
